{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, glob, re, unicodedata\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "\n",
    "INPUT_DIR   = r\"/content/KRUS-data-/dane_excel_kwartalne\"\n",
    "OUTPUT_CSV  = r\"./master_records.csv\"\n",
    "\n",
    "# ── nazwy specjalne ──\n",
    "REGION_NAMES = {\"region\",\"województwo\",\"wojewodztwo\",\"woj\",\"kraj\",\"państwo\",\"panstwo\"}\n",
    "PERIOD_NAMES = {\"okres\",\"period\",\"kwartał\",\"kwartal\",\"rok\",\"miesiąc\",\"miesiac\",\"year\",\"month\", \"okres według stanu\" }\n",
    "REGION_PATTERNS = [r\"\\bwoj(e|ewództw|ewodztw)o\", r\"\\bregion\\b\", r\"\\bkraj\\b\", r\"\\bpa(ns)?two\\b\"]\n",
    "PERIOD_PATTERNS = [\n",
    "    r\"\\bokres\\b\", r\"\\bperiod\\b\", r\"\\bkwarta(ł|l)\\b\", r\"\\brok\\b\", r\"\\bmiesi(?:ąc|ac)\\b\",\n",
    "    r\"okres\\s+wedlug\\s+stanu\", r\"okres\\s+wed[oó]ug\\s+stanu\"\n",
    "]\n",
    "\n",
    "# YYYY-Qn lub YYYYn wariant bez myślnika\n",
    "PERIOD_TOKEN_RE = re.compile(r\"^\\d{4}[-/]?q[1-4]$\", re.IGNORECASE)\n",
    "\n",
    "# ── mapa polskich miesięcy ──\n",
    "MONTHS_MAP = {\n",
    "    \"stycznia\": \"01\", \"lutego\": \"02\", \"marca\": \"03\", \"kwietnia\": \"04\",\n",
    "    \"maja\": \"05\", \"czerwca\": \"06\", \"lipca\": \"07\", \"sierpnia\": \"08\",\n",
    "    \"września\": \"09\", \"wrzesnia\": \"09\", \"października\": \"10\", \"pazdziernika\": \"10\",\n",
    "    \"listopada\": \"11\", \"grudnia\": \"12\"\n",
    "}\n",
    "\n",
    "# Funkcja zamieniająca np. \"31 marca 2025 r.\" → \"31.03.2025\"\n",
    "def normalize_polish_dates(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    def repl(match):\n",
    "        day = match.group(1).zfill(2)\n",
    "        month_name = match.group(2).lower()\n",
    "        year = match.group(3)\n",
    "        month_num = MONTHS_MAP.get(month_name)\n",
    "        if not month_num:\n",
    "            return match.group(0)  # jeśli nieznany miesiąc, zostawiamy oryginał\n",
    "        return f\"{day}.{month_num}.{year}\"\n",
    "\n",
    "    # wzorzec: np. \"31 marca 2025 r.\" albo \"7 kwietnia 2023 r.,\"\n",
    "    pattern = r\"\\b(\\d{1,2})\\s+(stycznia|lutego|marca|kwietnia|maja|czerwca|lipca|sierpnia|września|wrzesnia|października|pazdziernika|listopada|grudnia)\\s+(\\d{4})\\s*r?\\.?,?\"\n",
    "    return re.sub(pattern, repl, text, flags=re.IGNORECASE)\n",
    "\n",
    "def read_csv_any(path: str) -> pd.DataFrame:\n",
    "    for enc in (\"utf-8-sig\",\"utf-8\",\"cp1250\",\"iso-8859-2\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def strip_accents(s: str) -> str:\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s or \"\")\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    s = strip_accents(s).lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def find_special_col(columns: List[str], exact_set: set, patterns: List[str]) -> Optional[str]:\n",
    "    for c in columns:\n",
    "        if norm(c) in exact_set:\n",
    "            return c\n",
    "    for c in columns:\n",
    "        nc = norm(c)\n",
    "        if any(re.search(p, nc) for p in patterns):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def clean_value(v) -> str:\n",
    "    \"\"\"Zamiana NaN -> '', liczby z .0 -> int jako string.\"\"\"\n",
    "    if pd.isna(v):\n",
    "        return \"\"\n",
    "    try:\n",
    "        # liczby całkowite zapisane jako float z .0\n",
    "        if isinstance(v, float) and v.is_integer():\n",
    "            return str(int(v))\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = str(v)\n",
    "    if s.endswith(\".0\") and s.replace(\".0\",\"\").isdigit():\n",
    "        return s.replace(\".0\",\"\")\n",
    "    return s\n",
    "\n",
    "def process_file(path: str) -> pd.DataFrame:\n",
    "    df = read_csv_any(path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    dataset = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    # specjalne kolumny\n",
    "    region_col = find_special_col(list(df.columns), REGION_NAMES, REGION_PATTERNS)\n",
    "    period_col = find_special_col(list(df.columns), PERIOD_NAMES, PERIOD_PATTERNS)\n",
    "    typ_col    = next((c for c in df.columns if norm(c) == \"typ\"), None)\n",
    "\n",
    "    id_vars = []\n",
    "    if region_col: id_vars.append(region_col)\n",
    "    if period_col: id_vars.append(period_col)\n",
    "    if typ_col:    id_vars.append(typ_col)\n",
    "\n",
    "    value_vars = [c for c in df.columns if c not in id_vars]\n",
    "    if not value_vars:\n",
    "        return pd.DataFrame(columns=[\"dataset\",\"measure\",\"value\",\"region\",\"period\",\"typ\"])\n",
    "\n",
    "    long = df.melt(id_vars=id_vars, value_vars=value_vars,\n",
    "                   var_name=\"measure\", value_name=\"value\")\n",
    "\n",
    "    # podstawowe mapowanie\n",
    "    long[\"dataset\"] = dataset\n",
    "    long[\"region\"]  = long[region_col] if region_col else \"\"\n",
    "    long[\"period\"]  = long[period_col] if period_col else \"\"\n",
    "    long[\"typ\"]     = long[typ_col] if typ_col else \"\"\n",
    "\n",
    "    # DODATKOWO: jeśli measure wygląda jak 2025-Q1, uzupełnij period\n",
    "    mask_measure_period = long[\"measure\"].astype(str).str.match(PERIOD_TOKEN_RE)\n",
    "    long.loc[mask_measure_period & (long[\"period\"] == \"\"), \"period\"] = long.loc[mask_measure_period, \"measure\"]\n",
    "\n",
    "    # jeśli wartości w kolumnach id_vars wyglądają jak 2025-Q1, uzupełnij period\n",
    "    for idc in id_vars:\n",
    "        vals = long[idc].astype(str)\n",
    "        mask_row_period = vals.str.match(PERIOD_TOKEN_RE)\n",
    "        long.loc[mask_row_period & (long[\"period\"] == \"\"), \"period\"] = vals[mask_row_period]\n",
    "\n",
    "    # czyszczenie wartości\n",
    "    for col in [\"measure\",\"value\",\"region\",\"period\",\"typ\"]:\n",
    "        long[col] = long[col].map(clean_value)\n",
    "        long[col] = long[col].map(normalize_polish_dates)  # <<< DODANE TUTAJ\n",
    "\n",
    "    return long[[\"dataset\",\"measure\",\"value\",\"region\",\"period\",\"typ\"]]\n",
    "\n",
    "# ── główny przebieg ──\n",
    "parts: List[pd.DataFrame] = []\n",
    "for path in sorted(glob.glob(os.path.join(INPUT_DIR, \"*.csv\"))):\n",
    "    try:\n",
    "        part = process_file(path)\n",
    "        parts.append(part)\n",
    "        print(f\"[OK] {os.path.basename(path)} → {len(part)} rekordów\")\n",
    "    except Exception as e:\n",
    "        print(f\"[BŁĄD] {os.path.basename(path)}: {e}\")\n",
    "\n",
    "if parts:\n",
    "    master = pd.concat(parts, ignore_index=True)\n",
    "    master.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"Zapisano: {OUTPUT_CSV} ({len(master)} rekordów)\")\n",
    "else:\n",
    "    print(\"Brak danych wejściowych.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
